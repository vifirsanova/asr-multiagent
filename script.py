import argparse

parser = argparse.ArgumentParser(description="Инструмент для оценки качества стихотворений на основе базы знаний")

parser.add_argument("--data", type=str, required=True, help="Путь к хранилищу с тестовыми аудиозаписями")

args = parser.parse_args()

path = args.data

"""
TODO: извлечение и предобработка данных с целью оптимизации для нейросетевой обработки (нейросеть много кушает, поэтому лучше сразу сжать все файлы) 
    - описать логику для парсинга каталога с аудиозаписями
    - повытаскивать wav'ки
    - применить сжатие?
"""

# Все это надо упаковать в один *.sh, который 

# ОБРАБОТКА ВИСПЕРОМ
# - принимает на вход путь к аудиофайлу
# - запускает скрипт для whisper.cpp
# - передает выходные данные скрипта для виспера в temp 

# ФОРМИРОВАНИЕ ПРОМПТА
# скрипт, который склеивает данные виспера с системной ролью и путем к считыванию бд 
# для первых экспериментов подойдет JSON такого вида: https://github.com/vifirsanova/poetry-llm/blob/main/data/database.json
# ФОРМАТ БД: ID | META_DESCRIPTION | FUNCTION_NAME
# В промпте важно указать response_format: выбирать наиболее релевантную функцию и возвращать только ID распознанной функции в JSON 

# ОБРАБОТКА LLM
# - передаем данные из temp в скрипт для LLM 
#   - https://huggingface.co/Vikhrmodels
#   - https://huggingface.co/IlyaGusev
#   - https://huggingface.co/docs/transformers/en/quantization/gptq
# - в скрипте указываем путь 
# - удаляем данные из temp 

# 

def recognize(audio_data):
    """
    Функция, которая реализует функционал мультиагентного модуля
    :audiodata: считываем аудиофайл, преобразованным к числовым представлениям; это аудиозапись с командой юзера
    :return: ID распознанной функции 
    """

    # ОБРАБОТКА ВИСПЕРОМ
    # Обработка виспером: запускаем whisper.cpp напрямую с нужными параметрами
    #   - параметры: путь к файлу, tiny model (она хранится в каталоге), путь к выходным данным в папке temp
    
    # ФОРМИРОВАНИЕ ПРОМПТА
    # Склеивание распознанной команды с системной ролью и файлом с бд
    
    # ОБРАБОТКА LLM
    # Обработка LLM: запускаем скрипт с llama.cpp, в качестве промпта указываем путь к склеенному промпту
    # https://github.com/ggml-org/llama.cpp/tree/master/tools/run -> прописать здесь путь к входным / выходным 
    pass


# Предобработка, которая нам нужна: 
#   - квантованная модель whisper tiny
#   - квантовая llama cpp для русского языка 
#   - JSON-ка с БД-шкой
#   - промпт под мультиагент: prompt generation (DeepSeek / ChatGPT)
